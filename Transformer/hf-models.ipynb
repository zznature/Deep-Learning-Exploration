{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Chunks for training/model-00002-of-00006.safetensors:   0%|          | 0.00/4.86G [00:00<?, ?B/s]('Connection broken: IncompleteRead(110678290 bytes read, 389321710 more expected)', IncompleteRead(110678290 bytes read, 389321710 more expected))\n",
      "Downloading Chunks for training/model-00002-of-00006.safetensors: 5.36GB [28:59, 3.08MB/s]                             \n",
      "Combining Chunks: 100%|██████████| 4.86G/4.86G [00:04<00:00, 1.12GB/s]\n",
      "Downloading Chunks for training/model-00005-of-00006.safetensors:   0%|          | 0.00/4.86G [00:00<?, ?B/s]('Connection broken: IncompleteRead(110089 bytes read, 499889911 more expected)', IncompleteRead(110089 bytes read, 499889911 more expected))\n",
      "('Connection broken: IncompleteRead(28404461 bytes read, 471595539 more expected)', IncompleteRead(28404461 bytes read, 471595539 more expected))\n",
      "Downloading Chunks for training/model-00005-of-00006.safetensors:  49%|████▊     | 2.36G/4.86G [20:02<17:23, 2.40MB/s]('Connection broken: IncompleteRead(386717118 bytes read, 113282882 more expected)', IncompleteRead(386717118 bytes read, 113282882 more expected))\n",
      "Downloading Chunks for training/model-00005-of-00006.safetensors: 6.36GB [36:31, 2.90MB/s]                            \n",
      "Combining Chunks: 100%|██████████| 4.86G/4.86G [00:04<00:00, 1.13GB/s]\n",
      "Downloading Chunks for training/tokenizer.model: 100%|██████████| 500k/500k [00:04<00:00, 119kB/s]\n",
      "Combining Chunks: 100%|██████████| 500k/500k [00:00<00:00, 52.6MB/s]\n",
      "Downloading Chunks for training/arc_challenge.json: 100%|██████████| 656/656 [00:01<00:00, 437B/s]\n",
      "Combining Chunks: 100%|██████████| 656/656 [00:00<00:00, 164kB/s]\n",
      "Downloading Chunks for training/winogrande.json: 100%|██████████| 563/563 [00:01<00:00, 350B/s]\n",
      "Combining Chunks: 100%|██████████| 563/563 [00:00<00:00, 141kB/s]\n",
      "Downloading Chunks for training/gsm8k.json: 100%|██████████| 553/553 [00:01<00:00, 339B/s]\n",
      "Combining Chunks: 100%|██████████| 553/553 [00:00<00:00, 25.1kB/s]\n",
      "Downloading Chunks for training/model-00004-of-00006.safetensors: 100%|██████████| 4.86G/4.86G [24:37<00:00, 3.29MB/s] \n",
      "Combining Chunks: 100%|██████████| 4.86G/4.86G [00:04<00:00, 1.10GB/s]\n",
      "Downloading Chunks for training/model-00006-of-00006.safetensors: 100%|██████████| 2.68G/2.68G [12:26<00:00, 3.60MB/s]\n",
      "Combining Chunks: 100%|██████████| 2.68G/2.68G [00:02<00:00, 1.09GB/s]\n",
      "Downloading Chunks for training/mmlu.json: 100%|██████████| 14.3k/14.3k [00:01<00:00, 8.21kB/s]\n",
      "Combining Chunks: 100%|██████████| 14.3k/14.3k [00:00<00:00, 1.30MB/s]\n",
      "Downloading Chunks for training/tokenizer.json: 100%|██████████| 1.84M/1.84M [00:02<00:00, 640kB/s]\n",
      "Combining Chunks: 100%|██████████| 1.84M/1.84M [00:00<00:00, 72.2MB/s]\n",
      "Downloading Chunks for training/config.json: 100%|██████████| 691/691 [00:01<00:00, 414B/s]\n",
      "Combining Chunks: 100%|██████████| 691/691 [00:00<00:00, 38.4kB/s]\n",
      "Downloading Chunks for training/model.safetensors.index.json: 100%|██████████| 23.9k/23.9k [00:02<00:00, 10.6kB/s]\n",
      "Combining Chunks: 100%|██████████| 23.9k/23.9k [00:00<00:00, 1.11MB/s]\n",
      "Downloading Chunks for training/hellaswag.json: 100%|██████████| 648/648 [00:01<00:00, 422B/s]\n",
      "Combining Chunks: 100%|██████████| 648/648 [00:00<00:00, 36.0kB/s]\n",
      "Downloading Chunks for training/tokenizer_config.json: 100%|██████████| 1.07k/1.07k [00:02<00:00, 508B/s]\n",
      "Combining Chunks: 100%|██████████| 1.07k/1.07k [00:00<00:00, 47.4kB/s]\n",
      "Downloading Chunks for training/special_tokens_map.json: 100%|██████████| 414/414 [00:01<00:00, 255B/s]\n",
      "Combining Chunks: 100%|██████████| 414/414 [00:00<00:00, 25.9kB/s]\n",
      "Downloading Chunks for training/model-00001-of-00006.safetensors:   0%|          | 0.00/4.84G [00:00<?, ?B/s]('Connection broken: IncompleteRead(3249107 bytes read, 496750893 more expected)', IncompleteRead(3249107 bytes read, 496750893 more expected))\n",
      "Downloading Chunks for training/model-00001-of-00006.safetensors:  10%|█         | 500M/4.84G [08:17<1:09:51, 1.04MB/s]('Connection broken: IncompleteRead(54833425 bytes read, 445166576 more expected)', IncompleteRead(54833425 bytes read, 445166576 more expected))\n",
      "('Connection broken: IncompleteRead(92940228 bytes read, 407059772 more expected)', IncompleteRead(92940228 bytes read, 407059772 more expected))\n",
      "Downloading Chunks for training/model-00001-of-00006.safetensors:  83%|████████▎ | 4.00G/4.84G [15:41<01:27, 9.62MB/s] ('Connection broken: IncompleteRead(139145156 bytes read, 201251259 more expected)', IncompleteRead(139145156 bytes read, 201251259 more expected))\n",
      "Downloading Chunks for training/model-00001-of-00006.safetensors: 6.68GB [26:44, 4.16MB/s]                            \n",
      "Combining Chunks: 100%|██████████| 4.84G/4.84G [00:04<00:00, 1.11GB/s]\n",
      "Downloading Chunks for training/truthfulqa_mc.json: 100%|██████████| 645/645 [00:01<00:00, 368B/s]\n",
      "Combining Chunks: 100%|██████████| 645/645 [00:00<00:00, 45.7kB/s]\n",
      "Downloading Chunks for training/generation_config.json: 100%|██████████| 111/111 [00:01<00:00, 67.9B/s]\n",
      "Combining Chunks: 100%|██████████| 111/111 [00:00<00:00, 6.94kB/s]\n",
      "Downloading Chunks for training/model-00003-of-00006.safetensors:   0%|          | 0.00/4.86G [00:00<?, ?B/s]('Connection broken: IncompleteRead(1722693 bytes read, 498277307 more expected)', IncompleteRead(1722693 bytes read, 498277307 more expected))\n",
      "Downloading Chunks for training/model-00003-of-00006.safetensors:  10%|█         | 500M/4.86G [08:16<1:10:15, 1.03MB/s]('Connection broken: IncompleteRead(62608679 bytes read, 437391321 more expected)', IncompleteRead(62608679 bytes read, 437391321 more expected))\n",
      "Downloading Chunks for training/model-00003-of-00006.safetensors: 5.86GB [23:10, 4.21MB/s]                             \n",
      "Combining Chunks: 100%|██████████| 4.86G/4.86G [00:04<00:00, 1.08GB/s]\n",
      "Overwriting the current location of the File: C:\\Users\\zhoui9\\.cache\\sparsezoo\\neuralmagic\\llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\\training\\training/model-00002-of-00006.safetensors with the new location: C:\\Users\\zhoui9\\.cache\\sparsezoo\\neuralmagic\\llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\\training/model-00002-of-00006.safetensors.\n",
      "Downloading Chunks for training/model-00002-of-00006.safetensors:   0%|          | 0.00/4.86G [00:00<?, ?B/s]('Connection broken: IncompleteRead(10431213 bytes read, 489568787 more expected)', IncompleteRead(10431213 bytes read, 489568787 more expected))\n",
      "('Connection broken: IncompleteRead(61580483 bytes read, 438419517 more expected)', IncompleteRead(61580483 bytes read, 438419517 more expected))\n",
      "Downloading Chunks for training/model-00002-of-00006.safetensors:  10%|█         | 500M/4.86G [14:00<2:00:07, 605kB/s]('Connection broken: IncompleteRead(60806580 bytes read, 439193420 more expected)', IncompleteRead(60806580 bytes read, 439193420 more expected))\n",
      "Downloading Chunks for training/model-00002-of-00006.safetensors: 6.36GB [28:40, 3.70MB/s]                            \n",
      "Combining Chunks: 100%|██████████| 4.86G/4.86G [00:04<00:00, 1.03GB/s]\n",
      "Overwriting the current location of the File: C:\\Users\\zhoui9\\.cache\\sparsezoo\\neuralmagic\\llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\\training\\training/model-00005-of-00006.safetensors with the new location: C:\\Users\\zhoui9\\.cache\\sparsezoo\\neuralmagic\\llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\\training/model-00005-of-00006.safetensors.\n",
      "Downloading Chunks for training/model-00005-of-00006.safetensors:  41%|████      | 2.00G/4.86G [19:25<18:37, 2.56MB/s]('Connection broken: IncompleteRead(141965305 bytes read, 358034695 more expected)', IncompleteRead(141965305 bytes read, 358034695 more expected))\n",
      "Downloading Chunks for training/model-00005-of-00006.safetensors: 5.36GB [25:02, 3.56MB/s]                            \n",
      "Combining Chunks: 100%|██████████| 4.86G/4.86G [00:04<00:00, 1.03GB/s]\n",
      "Overwriting the current location of the File: C:\\Users\\zhoui9\\.cache\\sparsezoo\\neuralmagic\\llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\\training\\training/tokenizer.model with the new location: C:\\Users\\zhoui9\\.cache\\sparsezoo\\neuralmagic\\llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\\training/tokenizer.model.\n",
      "Downloading Chunks for training/tokenizer.model: 100%|██████████| 500k/500k [00:00<00:00, 680kB/s]\n",
      "Combining Chunks: 100%|██████████| 500k/500k [00:00<00:00, 21.3MB/s]\n",
      "Overwriting the current location of the File: C:\\Users\\zhoui9\\.cache\\sparsezoo\\neuralmagic\\llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\\training\\training/arc_challenge.json with the new location: C:\\Users\\zhoui9\\.cache\\sparsezoo\\neuralmagic\\llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\\training/arc_challenge.json.\n",
      "Downloading Chunks for training/arc_challenge.json: 100%|██████████| 656/656 [00:00<00:00, 1.15kB/s]\n",
      "Combining Chunks: 100%|██████████| 656/656 [00:00<00:00, 131kB/s]\n",
      "Overwriting the current location of the File: C:\\Users\\zhoui9\\.cache\\sparsezoo\\neuralmagic\\llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\\training\\training/winogrande.json with the new location: C:\\Users\\zhoui9\\.cache\\sparsezoo\\neuralmagic\\llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\\training/winogrande.json.\n",
      "Downloading Chunks for training/winogrande.json: 100%|██████████| 563/563 [00:00<00:00, 1.02kB/s]\n",
      "Combining Chunks: 100%|██████████| 563/563 [00:00<00:00, 66.1kB/s]\n",
      "Overwriting the current location of the File: C:\\Users\\zhoui9\\.cache\\sparsezoo\\neuralmagic\\llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\\training\\training/gsm8k.json with the new location: C:\\Users\\zhoui9\\.cache\\sparsezoo\\neuralmagic\\llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\\training/gsm8k.json.\n",
      "Downloading Chunks for training/gsm8k.json: 100%|██████████| 553/553 [00:00<00:00, 968B/s]\n",
      "Combining Chunks: 100%|██████████| 553/553 [00:00<00:00, 79.0kB/s]\n",
      "Overwriting the current location of the File: C:\\Users\\zhoui9\\.cache\\sparsezoo\\neuralmagic\\llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\\training\\training/model-00004-of-00006.safetensors with the new location: C:\\Users\\zhoui9\\.cache\\sparsezoo\\neuralmagic\\llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\\training/model-00004-of-00006.safetensors.\n",
      "Downloading Chunks for training/model-00004-of-00006.safetensors: 100%|██████████| 4.86G/4.86G [24:31<00:00, 3.30MB/s]\n",
      "Combining Chunks: 100%|██████████| 4.86G/4.86G [00:04<00:00, 1.00GB/s]\n",
      "Overwriting the current location of the File: C:\\Users\\zhoui9\\.cache\\sparsezoo\\neuralmagic\\llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\\training\\training/model-00006-of-00006.safetensors with the new location: C:\\Users\\zhoui9\\.cache\\sparsezoo\\neuralmagic\\llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\\training/model-00006-of-00006.safetensors.\n",
      "Downloading Chunks for training/model-00006-of-00006.safetensors: 100%|██████████| 2.68G/2.68G [03:44<00:00, 11.9MB/s]\n",
      "Combining Chunks: 100%|██████████| 2.68G/2.68G [00:02<00:00, 1.04GB/s]\n",
      "Overwriting the current location of the File: C:\\Users\\zhoui9\\.cache\\sparsezoo\\neuralmagic\\llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\\training\\training/mmlu.json with the new location: C:\\Users\\zhoui9\\.cache\\sparsezoo\\neuralmagic\\llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\\training/mmlu.json.\n",
      "Downloading Chunks for training/mmlu.json: 100%|██████████| 14.3k/14.3k [00:02<00:00, 5.53kB/s]\n",
      "Combining Chunks: 100%|██████████| 14.3k/14.3k [00:00<00:00, 1.30MB/s]\n",
      "Overwriting the current location of the File: C:\\Users\\zhoui9\\.cache\\sparsezoo\\neuralmagic\\llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\\training\\training/tokenizer.json with the new location: C:\\Users\\zhoui9\\.cache\\sparsezoo\\neuralmagic\\llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\\training/tokenizer.json.\n",
      "Downloading Chunks for training/tokenizer.json: 100%|██████████| 1.84M/1.84M [00:03<00:00, 600kB/s]\n",
      "Combining Chunks: 100%|██████████| 1.84M/1.84M [00:00<00:00, 123MB/s]\n",
      "Overwriting the current location of the File: C:\\Users\\zhoui9\\.cache\\sparsezoo\\neuralmagic\\llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\\training\\training/config.json with the new location: C:\\Users\\zhoui9\\.cache\\sparsezoo\\neuralmagic\\llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\\training/config.json.\n",
      "Downloading Chunks for training/config.json: 100%|██████████| 691/691 [00:02<00:00, 285B/s]\n",
      "Combining Chunks: 100%|██████████| 691/691 [00:00<00:00, 115kB/s]\n",
      "Overwriting the current location of the File: C:\\Users\\zhoui9\\.cache\\sparsezoo\\neuralmagic\\llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\\training\\training/model.safetensors.index.json with the new location: C:\\Users\\zhoui9\\.cache\\sparsezoo\\neuralmagic\\llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\\training/model.safetensors.index.json.\n",
      "Downloading Chunks for training/model.safetensors.index.json: 100%|██████████| 23.9k/23.9k [00:02<00:00, 9.39kB/s]\n",
      "Combining Chunks: 100%|██████████| 23.9k/23.9k [00:00<00:00, 2.00MB/s]\n",
      "Overwriting the current location of the File: C:\\Users\\zhoui9\\.cache\\sparsezoo\\neuralmagic\\llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\\training\\training/hellaswag.json with the new location: C:\\Users\\zhoui9\\.cache\\sparsezoo\\neuralmagic\\llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\\training/hellaswag.json.\n",
      "Downloading Chunks for training/hellaswag.json: 100%|██████████| 648/648 [00:02<00:00, 266B/s]\n",
      "Combining Chunks: 100%|██████████| 648/648 [00:00<00:00, 81.0kB/s]\n",
      "Overwriting the current location of the File: C:\\Users\\zhoui9\\.cache\\sparsezoo\\neuralmagic\\llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\\training\\training/tokenizer_config.json with the new location: C:\\Users\\zhoui9\\.cache\\sparsezoo\\neuralmagic\\llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\\training/tokenizer_config.json.\n",
      "Downloading Chunks for training/tokenizer_config.json: 100%|██████████| 1.07k/1.07k [00:02<00:00, 425B/s]\n",
      "Combining Chunks: 100%|██████████| 1.07k/1.07k [00:00<00:00, 133kB/s]\n",
      "Overwriting the current location of the File: C:\\Users\\zhoui9\\.cache\\sparsezoo\\neuralmagic\\llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\\training\\training/special_tokens_map.json with the new location: C:\\Users\\zhoui9\\.cache\\sparsezoo\\neuralmagic\\llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\\training/special_tokens_map.json.\n",
      "Downloading Chunks for training/special_tokens_map.json: 100%|██████████| 414/414 [00:02<00:00, 201B/s]\n",
      "Combining Chunks: 100%|██████████| 414/414 [00:00<00:00, 207kB/s]\n",
      "Overwriting the current location of the File: C:\\Users\\zhoui9\\.cache\\sparsezoo\\neuralmagic\\llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\\training\\training/model-00001-of-00006.safetensors with the new location: C:\\Users\\zhoui9\\.cache\\sparsezoo\\neuralmagic\\llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\\training/model-00001-of-00006.safetensors.\n",
      "Downloading Chunks for training/model-00001-of-00006.safetensors: 100%|██████████| 4.84G/4.84G [05:10<00:00, 15.6MB/s]\n",
      "Combining Chunks: 100%|██████████| 4.84G/4.84G [00:04<00:00, 1.01GB/s]\n",
      "Overwriting the current location of the File: C:\\Users\\zhoui9\\.cache\\sparsezoo\\neuralmagic\\llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\\training\\training/truthfulqa_mc.json with the new location: C:\\Users\\zhoui9\\.cache\\sparsezoo\\neuralmagic\\llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\\training/truthfulqa_mc.json.\n",
      "Downloading Chunks for training/truthfulqa_mc.json: 100%|██████████| 645/645 [00:02<00:00, 309B/s]\n",
      "Combining Chunks: 100%|██████████| 645/645 [00:00<00:00, 43.0kB/s]\n",
      "Overwriting the current location of the File: C:\\Users\\zhoui9\\.cache\\sparsezoo\\neuralmagic\\llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\\training\\training/generation_config.json with the new location: C:\\Users\\zhoui9\\.cache\\sparsezoo\\neuralmagic\\llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\\training/generation_config.json.\n",
      "Downloading Chunks for training/generation_config.json: 100%|██████████| 111/111 [00:02<00:00, 46.4B/s]\n",
      "Combining Chunks: 100%|██████████| 111/111 [00:00<00:00, 15.9kB/s]\n",
      "Overwriting the current location of the File: C:\\Users\\zhoui9\\.cache\\sparsezoo\\neuralmagic\\llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\\training\\training/model-00003-of-00006.safetensors with the new location: C:\\Users\\zhoui9\\.cache\\sparsezoo\\neuralmagic\\llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\\training/model-00003-of-00006.safetensors.\n",
      "Downloading Chunks for training/model-00003-of-00006.safetensors: 100%|██████████| 4.86G/4.86G [04:40<00:00, 17.3MB/s]\n",
      "Combining Chunks: 100%|██████████| 4.86G/4.86G [00:04<00:00, 1.04GB/s]\n",
      "Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00,  8.23it/s]\n",
      "Downloading Chunks for deployment/tokenizer_config.json: 100%|██████████| 1.07k/1.07k [00:02<00:00, 444B/s]\n",
      "Combining Chunks: 100%|██████████| 1.07k/1.07k [00:00<00:00, 152kB/s]\n",
      "Downloading Chunks for deployment/tokenizer.model: 100%|██████████| 500k/500k [00:03<00:00, 165kB/s]\n",
      "Combining Chunks: 100%|██████████| 500k/500k [00:00<00:00, 33.3MB/s]\n",
      "Downloading Chunks for deployment/tokenizer.json: 100%|██████████| 1.84M/1.84M [00:03<00:00, 550kB/s]\n",
      "Combining Chunks: 100%|██████████| 1.84M/1.84M [00:00<00:00, 128MB/s]\n",
      "Downloading Chunks for deployment/special_tokens_map.json: 100%|██████████| 414/414 [00:02<00:00, 171B/s]\n",
      "Combining Chunks: 100%|██████████| 414/414 [00:00<00:00, 41.4kB/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LlamaTokenizerFast' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 18\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msparseml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      9\u001b[0m     SparseAutoModelForCausalLM, SparseAutoTokenizer, load_dataset, compress\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m SparseAutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzoo:llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     14\u001b[0m     device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m )\n\u001b[0;32m     16\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mSparseAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzoo:llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m---> 18\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(model\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     19\u001b[0m dataset \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHuggingFaceH4/helpful_instructions\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LlamaTokenizerFast' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"HuggingFaceH4/helpful_instructions\", \n",
    "              trust_remote_code=True,\n",
    "              # download_mode=\"reuse_cache_if_exists\"\n",
    "                       )\n",
    "\n",
    "from sparseml.transformers import (\n",
    "    SparseAutoModelForCausalLM, SparseAutoTokenizer, load_dataset, compress\n",
    ")\n",
    "\n",
    "model = SparseAutoModelForCausalLM.from_pretrained(\n",
    "    \"zoo:llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "tokenizer = SparseAutoTokenizer.from_pretrained(\n",
    "    \"zoo:llama2-7b-open_platypus_orca_llama2_pretrain-pruned60\"\n",
    ").to(model.device)\n",
    "dataset = load_dataset(\"HuggingFaceH4/helpful_instructions\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hfmodels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
